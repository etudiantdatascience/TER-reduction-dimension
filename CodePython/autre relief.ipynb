{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def FonctionImportDonnees(chemin):\n",
    "    \"\"\"\n",
    "        importe les données du fichier excel, après expertise\n",
    "    \"\"\"\n",
    "    donnees=pd.ExcelFile(chemin).parse(1) #Sélectionne la première feuille\n",
    "    donnees=donnees.drop(index=[960,952]) #Supprime les lignes avec trop de NA\n",
    "    donnees=donnees.drop('5°C T50 (h)',axis=1).drop('5°C T50 (j)',axis=1).drop('5°C TMG (h)',axis=1) #Supprime les colonnes avec information identique, ou avec trop de NA\n",
    "    \n",
    "    liste=[]\n",
    "    col={}\n",
    "    j=0\n",
    "    \n",
    "    for i in range(10,16): #Expertise: création des données de croissance\n",
    "        a=donnees.columns[i]\n",
    "        b=donnees.columns[i+1]\n",
    "        liste.append(donnees[b]-donnees[a])\n",
    "        c='v'+a+'-'+b\n",
    "        col[j]=c.replace(' ','')\n",
    "        j=j+1\n",
    "    croissance=pd.DataFrame(liste).T\n",
    "    croissance=croissance.rename(col, axis='columns')\n",
    "    donnees=pd.concat([donnees,croissance],axis=1).dropna()\n",
    "    donnees.set_index('rep')\n",
    "    \n",
    "    donnees=donnees[['Bancs', 'Pop', 'Echantillon', 'rep', 'N° rep', 'camera', 'semis','zone', '5°C TMG (j)', 'Aire sous la courbe', 'v15j-16j', 'v16j-17j', 'v17j-18j','v18j-19j', 'v19j-20j', 'v20j-21j']]\n",
    "    \n",
    "    quanti=['5°C TMG (j)', 'Aire sous la courbe', 'v15j-16j', 'v16j-17j', 'v17j-18j','v18j-19j', 'v19j-20j', 'v20j-21j']\n",
    "    quali=['Bancs', 'Pop', 'N° rep', 'camera', 'semis','zone']\n",
    "    \n",
    "    return donnees,quanti,quali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "donnees,quanti,quali=FonctionImportDonnees(\"https://raw.githubusercontent.com/etudiantdatascience/TER-reduction-dimension/master/Data/semis.xlsx\")\n",
    "for variableQuali in quali:\n",
    "    valeur=donnees[variableQuali].drop_duplicates().values\n",
    "    donnees[variableQuali]=donnees[variableQuali].replace(valeur,list(range(len(valeur))))\n",
    "\n",
    "features, labels = donnees[quanti],donnees['zone']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from skrebate import ReliefF\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "clf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),\n",
    "                    RandomForestClassifier(n_estimators=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7931251349347151\n"
     ]
    }
   ],
   "source": [
    "genetic_data = pd.read_csv('https://github.com/EpistasisLab/scikit-rebate/raw/master/data/'\n",
    "                           'GAMETES_Epistasis_2-Way_20atts_0.4H_EDM-1_1.tsv.gz',\n",
    "                           sep='\\t', compression='gzip')\n",
    "\n",
    "features, labels = genetic_data.drop('class', axis=1).values, genetic_data['class'].values\n",
    "\n",
    "clf = make_pipeline(ReliefF(n_features_to_select=2, n_neighbors=100),\n",
    "                    RandomForestClassifier(n_estimators=100))\n",
    "\n",
    "print(np.mean(cross_val_score(clf, features, labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ReliefF as ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class ReliefF in module ReliefF.ReliefF:\n",
      "\n",
      "class ReliefF(builtins.object)\n",
      " |  ReliefF(n_neighbors=100, n_features_to_keep=10)\n",
      " |  \n",
      " |  Feature selection using data-mined expert knowledge.\n",
      " |  \n",
      " |  Based on the ReliefF algorithm as introduced in:\n",
      " |  \n",
      " |  Kononenko, Igor et al. Overcoming the myopia of inductive learning\n",
      " |  algorithms with RELIEFF (1997), Applied Intelligence, 7(1), p39-55\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=100, n_features_to_keep=10)\n",
      " |      Sets up ReliefF to perform feature selection.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      n_neighbors: int (default: 100)\n",
      " |          The number of neighbors to consider when assigning feature\n",
      " |          importance scores.\n",
      " |          More neighbors results in more accurate scores, but takes longer.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Computes the feature importance scores from the training data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X: array-like {n_samples, n_features}\n",
      " |          Training instances to compute the feature importance scores from\n",
      " |      y: array-like {n_samples}\n",
      " |          Training labels\n",
      " |      }\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      None\n",
      " |  \n",
      " |  fit_transform(self, X, y)\n",
      " |      Computes the feature importance scores from the training data, then\n",
      " |      reduces the feature set down to the top `n_features_to_keep` features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X: array-like {n_samples, n_features}\n",
      " |          Training instances to compute the feature importance scores from\n",
      " |      y: array-like {n_samples}\n",
      " |          Training labels\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_reduced: array-like {n_samples, n_features_to_keep}\n",
      " |          Reduced feature matrix\n",
      " |  \n",
      " |  transform(self, X)\n",
      " |      Reduces the feature set down to the top `n_features_to_keep` features.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X: array-like {n_samples, n_features}\n",
      " |          Feature matrix to perform feature selection on\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_reduced: array-like {n_samples, n_features_to_keep}\n",
      " |          Reduced feature matrix\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors defined here:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ok.ReliefF)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
