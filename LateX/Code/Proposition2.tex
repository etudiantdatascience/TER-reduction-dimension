\documentclass[12pt]{report}
\usepackage{lmodern}  % Police pdf
\usepackage[french]{babel} % Document en fran\c{c}ais
\usepackage[utf8]{inputenc} % Encodage en utf8
\usepackage[T1]{fontenc} % Typographie fran\c{c}aise
\usepackage{textcomp}
\usepackage[a4paper]{geometry} % Dimension de la page fran\c{c}aise
\usepackage{amsmath, amssymb} % Plus de maths 
\usepackage{graphicx} % Pour ins\'erer des images
\usepackage{xcolor} % Pour la couleur
\usepackage{hyperref} % Pour cr\'eer la navigation hypertext dans les fichiers pdf ( \`a charger apr\`es babel)
\hypersetup{backref=true, pagebackref=true,colorlinks=true,linkcolor=black, urlcolor=blue,} % Options pour les liens hypertextes
\usepackage{tikz} % Pour faire des figures
\usepackage{here} % Pour placer les images

\usepackage{booktabs}
\usepackage[normalem]{ulem}
\useunder{\uline}{\ul}{}

\title{\textbf{Comparaison de méthodes de réduction de dimension pour des analyses de données biologiques}} 
\author{Reunan Bellec \& Malo Gillard \\ Enseignant référent : David Rousseau}
\date{\today} % Date

\begin{document}

\maketitle

\newpage

\tableofcontents

\newpage
\part{Introduction}

\section*{Introduction du contexte}

Le dérèglement climatique, le développement de nouvelles maladies des plantes, la maîtrise des rendements, amènent les états et l’ensemble des acteurs de l’agriculture en charge de la sélection variétale, à identifier des semences performantes, résistantes aux maladies, à des périodes de sécheresse ou de brusques variations environnementales durant leur développement. Ces travaux peuvent bénéficier d’avancées technologiques récentes en matière de traitements de l’information, applicables sur de larges populations de plantes. Une échelle particulièrement importante est celle de la graine, dont la qualité germinative conditionne la suite du développement de la plante. Dans ce projet annuel, nous nous intéressons à un échantillon de graines de betterave sucrière pour laquelle la France est l’un des plus gros producteurs au monde.\\

L'objectif de l'expérience est d'élargir la variabilité génétique de la betterave, dans le but de la rendre plus compétitive, en doublant le rythme de croissance annuelle de son rendement en sucre.
Des tests ont alors été réalisés sur différents génotypes de betteraves (200 individus) pour étudier leur germination.
À partir des résultats obtenus sur les semences sélectionnées, nous observons des différences, que l'on cherche à caractériser. Parmi les 200 génotypes, diverses variables sont à expliquer, telles que la surface, la longueur, la largeur, l'imbibition, la vitesse de germination par exemple.\\

\section*{Introduction du sujet}

Le but de ce projet est de comparer des méthodes visant à diminuer la dimension des données, à réduire le nombre de variables, pour pouvoir répondre à une problématique de manière efficace. INSÉRER PARAGRAPHE SUR LES PROBLEMES GÉNÉRER PAR LES TROP GRANDES DIMENSIONS. \\

La problématique au centre de ce projet est de vérifier par visualisation des données que des biais d'expérimentation ne sont pas introduit dans l'étude des génotypes. 
Pour se faire, nous allons donc considérer plusieurs méthodes:  PCA, t-SNE, Random Forest, LDA, ISOMAP, Relief. \\

Nous commencerons par un rappel sur les notions d'apprentissages, supervisé et non supervisé.
Nous étudierons ensuite chaque méthode en détail, pour ensuite pouvoir les appliquer à notre jeu de données principal, les données issues de l'expérience de germination.
Enfin, nous comparerons les résultats obtenus.


\section*{Introduction à la réduction de dimension}

Le but de ce projet est de comparer des méthodes visant à diminuer la dimension des données, à réduire le nombre de variables, pour pouvoir répondre à une problématique de manière efficace. INSÉRER PARAGRAPHE SUR LES PROBLEMES GÉNÉRER PAR LES TROP GRANDES DIMENSIONS. \\

La problématique au centre de ce projet est de vérifier par visualisation des données que des biais d'expérimentation ne sont pas introduit dans l'étude des génotypes. 
Pour se faire, nous allons donc considérer plusieurs méthodes:  PCA, t-SNE, Random Forest, LDA, ISOMAP, Relief. \\

Nous commencerons par un rappel sur les notions d'apprentissages, supervisé et non supervisé.
Nous étudierons ensuite chaque méthode en détail, pour ensuite pouvoir les appliquer à notre jeu de données principal, les données issues de l'expérience de germination.
Enfin, nous comparerons les résultats obtenus.

\section*{Notions élementaires}

\paragraph{Apprentissage supervisé}\mbox{}\\

Les tableaux de données sont constitués d'individus décrits par plusieurs variables dont l'une d'entre elles est qualitative. On veut fabriquer une fonction qui prédit cette variable par un modèle mathématique.


\newpage
\part{Les méthodes}


\section{Méthodes par sélection}


\subsection{Apprentissage supervisé}

\subsubsection{Random Forest}

Arbre de décision

On veut construire des sous-groupes les plus homogènes du point de vue de la variable à prédire.

\paragraph{Mathématiques}
 
\paragraph{Informatique}\mbox{}\\

\paragraph{Explication simplifiée}. 

\subsection{Apprentissage non-supervisé}

L’algorithme est autonome, il ne connaît pas les exemples de résultats attendus en sortie. Il va détecter les similarités dans les données qu’il reçoit et les organiser en fonction de ces
dernières

\subsubsection{Relief}

Méthode de filtrage pour la sélection de variables explicatives. Principe : calculer une mesure globale de la pertinence des caractéristiques des données en accumulant la
différence des distances entre des exemples
Trouve le plus proche voisin dans la même classe et le plus proche se trouvant dans une classe différente. Identification des différences de valeurs pour les variables

\paragraph{Mathématiques}
\paragraph{Informatiques}
\paragraph{Explication simplifiée}


\section{Méthodes par transformation}

Dans cette section, les méthodes traitées sont celles qui effectuent une transformation sur les variables. Une fois, ces méthodes appliquées, les individus peuvent être représenté dans un espace de dimension réduite où les axes sont nouveaux. Un nouveau système de représentation est ainsi construit.

\subsection{Apprentissage supervisé}

\subsubsection{LDA}

\paragraph{Mathématiques}
\paragraph{Informatiques}
\paragraph{Explication simplifiée}

\subsubsection{SIMCA}

\paragraph{Mathématiques}
\paragraph{Informatiques}
\paragraph{Explication simplifiée}

\subsection{Apprentissage non-supervisé}

\subsubsection{PCA}

\paragraph{Explication simplifiée}\mbox{}\\

Le but de l'analyse en composante princiaple est de partir des variables corrélées, pour obtenir des variables non corrélées (composantes principales/ axes principaux) et ainsi éliminer l’information récurrente/redondante. Les variables utilisées sont donc toutes quantitatives. Les nouvelles composantes synthétisant l'information seront rangées par ordre croissant de leur contenu en information. L'information considérée ici est l'inertie. La corrélatio, mesure de liaison entre deux variablees, est un point clé de cette méthode.

On peut savoir l'importance des axes par leur pourcentage de l'nertie associé.
La notion de réduction de dimension intervient lors du choix du nombre de composante pour obtenir la réprésentation la plus fidèle possible.

Lorsque les données sont ordonnées dans une matrice X, avec les individus en lignes et les variables en colonnes, l'étude des lignes portera sur les distances entre individus et l'étude des colonnes sur les relations entre variables.

\paragraph{Mathématiques}
La solution mathématique de ces études revient à trouver une matrice de rang donné la plus proche de celle-ci. 
Le but de cette méthode est de projeter orhtogonalement le nuage de points dans un sous-espace de dimension réduite avec une réprésentation fidèle des distances initiales.
On va alors décomposer la matrice X par SVD: $ X=U \Delta V = \sum_{i}{ s_{i}u_{i}v_{i}^{t}}$
Ainsi, le sous espace $Vect(v_{1},...,v_{s})$ est le sous espace de dimension s optimisant l'inertie projetée.
L'inertie de ce sous-espace est $s_{1}^{2}+...+s_{s}^{2}$, la variance de $F{i}$ est $s_{i}^{2}$.
Les projections sur $v_{s}$, $F_{s}=XQu_{s}$ correspondent aux composantes principales.
Les nouvelles variables définies par les colonnes de $F_{L} =XQV$ sont non corrélées.
Où Q EST LA MÉTRIQUE.

\paragraph{Utilisation pratique/informatique}

Paramètres à régler\\




Sorties \\

Qualité de représentation globale: partie d'intertie expliquée par l'axe de projection. L'inertie expliquée par les k premiers axes factoriels:\\ $ \frac {\sum_{s=1}^{k}{\lambda_{s}}}{\sum_{s=1}^{k}{\lambda_{s}}}$

Qualité de représentation ou $cos^{2}$, d'un individu ou d'une variable suivant un axe ou un plan sa part d'inertie projetée, égale au $cos^{2}=\frac {F_{s}^{2}(i)}{\sum_{s=1}^{p}{F_{s}^{2}(k)}}$

\subsubsection{Isomap}

\paragraph{Mathématiques}
\paragraph{Informatiques}
\paragraph{Explication simplifiée}

\subsubsection{T-SNE}

Schéma illustratif à ajouter.
Méthode non-linéaire.
Théorie de l'information.
Distribution de probabilité.
Divergence KL.
Attraction des points vers les points qui lui sont proches dans l’espace de grande dimension, inversement les points qui sont éloignés dans l’espace d’origine se rejettent. Déplacement des points petits à petits, individuellement.

\paragraph{Mathématiques}
\paragraph{Informatiques}

perplexity 


early_exaggeration


learning_rate 


metric: Choix de la métrique utilisée pour calculer la distance entre individus 

\paragraph{Explication simplifiée}

\newpage
\part{Données}

\section{Introduction des données}

Dans le but d'analyser la germination, de la semence sèche jusqu’à la percée de la radicule, on utilise l'imagerie automatisée sur des semences semées sur des Tables de Jacobsen (bancs de germination).
Les essais de germination sont menés à 5°C dans un module climatique sur 2 tables de Jacobsen. Les sondes de température de régulation et surveillance des essais ont été étalonnées avant le début de l’expérimentation. Les 2 tables de Jacobsen ont été cartographiées pour la température en 5 points.
Chaque table dispose de 4 caméras sous lesquels sont semées 600 semences par caméra par zone de 5x5 semences. Il y a 24 zones / série d’image et 25 semences par zone. Les zones et semences sont codés « ligne colonne ».
3 semis on été réalisés en parallèle sur les 2 tables dans l’ordre des populations.
Les images acquises pendant 21 jours ont été analysées et à partir des mesures sur images l’heure de germination a été détectée sur chaque semence ainsi que des caractéristiques complémentaires.\\

    
\section{Expertise}

La première tâche à réaliser avant de travailler sur les données au travers des différentes méthodes de réduction de dimension est l'expertise, c'est à dire la préparation, le nettoyage des données. Nous avons réfléchis avec un point de vue autre que celui de data scientist : qu'est-il bon de garder ou d'écarter dans le jeu de données, faut-il rajouter des variables explicatives, et pourquoi.\\

Comme nous nous intéressons à l'évolution des germinations jour par jour, nous avons écarté les variables qui s'exprimaient en heures, c'est à dire les variables \textbf{5\textdegree C TMG (h)} et \textbf{5\textdegree C T50 (h)}, et gardé celles qui s'exprimaient en jours, \textbf{5\textdegree C TMG (j)} et \textbf{5\textdegree C T50 (j)}.\\
Cependant, cette dernière comprenait un nombre important d'entrées "Nan" (plus de la moitié), ce qui signifie qu'il n'a pas été possible de calculer le délai nécessaire pour obtenir 50\% de germination pour plus de la moitié des individus. Nous l'avons donc également écartée car elle présentait peu d'intérêt dans notre étude.\\

Nous avons ensuite rajouté 6 variables \textbf{'v15-16j'}, \textbf{'v16-17j'}, \textbf{'v17-18j'}, \textbf{'v18-19j'}, \textbf{'v19-20j'}, et \textbf{'v20-21j'},  pour exprimer la vitesse de germination de chaque individu jour après jour à partir du jour 15.

\part{Explication des paramètres}

Explication des paramètres:\\
\begin{table}[!h]
\begin{tabular}{@{}|l|l|@{}}
\toprule
n\_estimators       & \begin{tabular}[c]{@{}l@{}}La précision a tendance à augmenter quand le nombre d'arbres\\ 			augmente, néanmoins, le temps de calcul est de plus en plus long.\end{tabular} \\ \midrule  \\ \hline \hline
max\_features       & \begin{tabular}[c]{@{}l@{}}Nombre de features à considérer pour la meilleure séparation\\ 			d'un noeud\end{tabular}                                                        \\ \midrule \hline \hline
max\_depth          & profondeur maximale de l'arbre                                                                                                                                              \\ \midrule \hline \hline
min\_samples\_split & Nombre minimal d'observations pour séparer un noeud                                                                                                                         \\ \midrule \hline \hline
criterion           & \begin{tabular}[c]{@{}l@{}}Critère de découpe des noeuds, Gini pour la précision,\\ 			Entropy pour un gain d'information\end{tabular}                                      \\ \midrule \hline \hline
random\_state       & \begin{tabular}[c]{@{}l@{}}si la méthode repose sur de l'aléatoire, fixe le générateur\\ 			pour reproduire les résultats.\end{tabular}                                     \\ \bottomrule \hline \hline
\end{tabular}
\end{table}
\\


\begin{table}[!h]
\begin{tabular}{@{}|l|l|@{}}
\toprule
n\_neighbors         & nombre de voisins à considérer pour chaque point                                                                                                       \\ \midrule
n\_components        & nombre de dimensions auquel on veut réduire notre espace de variables                                                                                  \\ \midrule
eigen\_solver        & méthode de décomposition en éléments propres souhaitée (par défaut = 'auto',  utilise la méthode la plus adaptée)                                      \\ \midrule
tol ; max\_iter      & dépendent du choix de eigen\_solver si == 'dense'                                                                                                      \\ \midrule
path\_method         & méthode utilisée pour trouver le plus court chemin/distance géodésique, par exemple Dijkstra (par défaut = 'auto', utilise la méthode la plus adaptée) \\ \midrule
neighbors\_algorithm & algorithme utilisée pour la recherche des plus proches voisins (par défaut = 'auto', utilise la méthode la plus adaptée)                               \\ \midrule
n\_jobs              & entier utilisé pour indiquer quelle quantité de mémoire on souhaite utiliser pour faire tourner l'algorithme                                           \\ \bottomrule
\end{tabular}
\end{table}


\newpage
\part{Résultats}

\newpage
\part{Comparaison des méthodes}

Les variables les plus importantes selon les méthodes:

\begin{table}[!h]
\begin{tabular}{@{}|l|l|l|@{}}
\toprule
Méthode       & Dimensions retenues/ importantes                                                                                                                                              & Remarque sur la méthode \\ \midrule
PCA           & \begin{tabular}[c]{@{}l@{}}Axe 1 :\\ 			5°C TMG (j)\\ 			Aire sous la courbe\\ 			v15j-16j\\ 			\\ \\ 			\\ 			Axe 2 :\\ 			v17j-18j\\ 			v18j-19j\\ 			v16j-17j\end{tabular} &                         \\ \midrule
Relief & \begin{tabular}[c]{@{}l@{}}5°C TMG (j)\\ 			Aire sous la courbe\end{tabular}                                                                                                  &                         \\ \midrule
Random Forest & \begin{tabular}[c]{@{}l@{}}5°C TMG (j)\\ 			Aire sous la courbe\end{tabular}                                                                                                  &                         \\ \bottomrule
\end{tabular}
\end{table}

Note:

Pour les méthodes par sélection de variables, les variables les plus importantes sont tout simplement celles sélectionnées, tandis que pour les méthodes par transformation il est nécessaire de regarder les contributions des anciennes variables aux nouvelles.

\newpage
\part{Conclusion}











\end{document}